{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080 Ti, compute capability 8.6\n",
      "Running on Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], Tensorflow 2.8.0-rc0.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, Model, mixed_precision\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os, sys\n",
    "import re\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "print(f'Running on Python {sys.version}, Tensorflow {tf.__version__}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('1137582001-1137583000.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # clean unicode stuff\n",
    "    # text = text.replace('\\n', '<NEWLINE>')  # to see if without newline generated stuff works\n",
    "    # text = re.sub(r'_+', ' _ ', text)  # replace all underscores with single underscore\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "title = []\n",
    "category = []\n",
    "desc = []\n",
    "img = []\n",
    "data_loss_allowed = 0.8  # if cleaned data is less than 80% of length of original data, ditch it\n",
    "for i, v in data.items():\n",
    "    v['categories'] = ', '.join(v['categories'])  # expand cat list into string, see if works, if not, use one hot encoding but thats more complicated\n",
    "    new_title = clean(v['name'])\n",
    "    new_cat = clean(v['categories'])\n",
    "    new_desc = clean(v['desc'])\n",
    "    if len(new_title) > len(v['name'])*data_loss_allowed and len(new_cat) > len(v['categories'])*data_loss_allowed and len(new_desc) > len(v['desc'])*data_loss_allowed:\n",
    "        title.append(new_title)\n",
    "        category.append(new_cat)\n",
    "        desc.append(new_desc)\n",
    "        img.append(f'imgs/{i}.jpg')\n",
    "\n",
    "title = np.array(title)\n",
    "category = np.array(category)\n",
    "desc = np.array(desc)\n",
    "img = np.array(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " title_input (InputLayer)       [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " category_input (InputLayer)    [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " BERT_tokenizer (KerasLayer)    {'input_type_ids':   0           ['title_input[0][0]',            \n",
      "                                (None, 128),                      'category_input[0][0]']         \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'sequence_output':  109482241   ['BERT_tokenizer[0][0]',         \n",
      "                                 (None, 128, 768),                'BERT_tokenizer[0][1]',         \n",
      "                                 'pooled_output': (               'BERT_tokenizer[0][2]',         \n",
      "                                None, 768),                       'BERT_tokenizer[1][0]',         \n",
      "                                 'default': (None,                'BERT_tokenizer[1][1]',         \n",
      "                                768),                             'BERT_tokenizer[1][2]']         \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 1536)    0           ['BERT_encoder[0][14]',          \n",
      "                                                                  'BERT_encoder[1][14]']          \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 128, 512)     4196352     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 128, 256)     787456      ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128, 512)     131584      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " description_output (Dense)     (None, 128, 30522)   15657786    ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 130,255,419\n",
      "Trainable params: 20,773,178\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "preprocessor = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "vocab_size = preprocessor.tokenize.get_special_tokens_dict()[\"vocab_size\"].numpy()\n",
    "preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', name='BERT_tokenizer')\n",
    "desc = preprocessing_layer(desc)['input_word_ids']\n",
    "\n",
    "title_input = Input(shape=(), name='title_input', dtype=tf.string)\n",
    "category_input = Input(shape=(), name='category_input', dtype=tf.string)\n",
    "# img_input = Input(shape=(224, 224, 3), name='img_input', dtype=tf.float32)\n",
    "\n",
    "title_embeddings = preprocessing_layer(title_input)\n",
    "category_embeddings = preprocessing_layer(category_input)\n",
    "# extract image features\n",
    "\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4', trainable=False, name='BERT_encoder')\n",
    "title_embeddings = encoder(title_embeddings)\n",
    "title_embeddings = title_embeddings['sequence_output']\n",
    "category_embeddings = encoder(category_embeddings)\n",
    "category_embeddings = category_embeddings['sequence_output']\n",
    "x = concatenate([title_embeddings, category_embeddings])\n",
    "x = LSTM(512, return_sequences=True)(x)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "description_output = Dense(vocab_size, name='description_output', activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[title_input, category_input], outputs=[description_output])\n",
    "plot_model(model, \"model.png\", show_shapes=True)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)],\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0, patience=13, verbose=1,\n",
    "                                     mode='auto', baseline=None, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=10, verbose=1)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 31s 2s/step - loss: 9.1737 - accuracy: 0.5642 - val_loss: 6.9266 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 18s 3s/step - loss: 4.5167 - accuracy: 0.6728 - val_loss: 3.5319 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 473ms/step - loss: 3.6630 - accuracy: 0.6728 - val_loss: 3.5065 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 3s 477ms/step - loss: 3.1117 - accuracy: 0.6728 - val_loss: 3.3411 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 4s 486ms/step - loss: 2.9807 - accuracy: 0.6728 - val_loss: 3.2517 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 506ms/step - loss: 2.9295 - accuracy: 0.6728 - val_loss: 3.1782 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 2.8840 - accuracy: 0.6728 - val_loss: 3.1328 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 3s 491ms/step - loss: 2.8598 - accuracy: 0.6728 - val_loss: 3.0991 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 2.8336 - accuracy: 0.6728 - val_loss: 3.0728 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 2.8064 - accuracy: 0.6728 - val_loss: 3.0269 - val_accuracy: 0.6845 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit({\"title_input\": title, \"category_input\": category}, {\"description_output\": desc}, validation_split=0.2,\n",
    "                    batch_size=64, epochs=10, callbacks=callbacks, use_multiprocessing=True, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone XS (512GB) READ BEFORE DM Mobile Phones & Gadgets, Mobile Phones, iPhone, iPhone X Series\n"
     ]
    }
   ],
   "source": [
    "title_to_pred = title[0]\n",
    "category_to_pred = category[0]\n",
    "print(title_to_pred, category_to_pred)\n",
    "# title_to_pred = preprocessing_layer([title_to_pred])['input_word_ids']\n",
    "# category_to_pred = preprocessing_layer([category_to_pred])['input_word_ids']\n",
    "pred = model.predict({\"title_input\": np.array([title_to_pred]), \"category_input\": np.array([category_to_pred])})\n",
    "pred = pred.squeeze()\n",
    "pred = np.argmax(pred, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}